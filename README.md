# Chat Bot Project

A modern chat interface built with Astro, TypeScript, and Ollama integration. This project features a responsive UI with dark/light theme support, image upload capabilities, and both text and vision-based AI interactions.

## ğŸš€ Features

- **Real-time Chat Interface**: Smooth, responsive chat experience
- **Dark/Light Theme**: Automatic theme detection with manual toggle
- **Image Support**: Upload and process images in conversations
- **AI Integration**:
  - Text-based chat using `llama3.2`
  - Vision capabilities using `llama3.2-vision`
- **Responsive Design**: Works seamlessly across different screen sizes
- **TypeScript Support**: Full type safety throughout the application
- **Stream Responses**: Real-time streaming of AI responses

## ğŸ› ï¸ Tech Stack

- **Framework**: [Astro](https://astro.build)
- **Styling**: [Tailwind CSS](https://tailwindcss.com)
- **AI Integration**: [Ollama](https://ollama.ai)
- **Testing**: Vitest
- **Language**: TypeScript

## ğŸ“¦ Project Structure

```
/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/         # UI Components
â”‚   â”‚   â”œâ”€â”€ ChatForm.astro
â”‚   â”‚   â”œâ”€â”€ ChatHeader.astro
â”‚   â”‚   â”œâ”€â”€ ChatMessage.astro
â”‚   â”‚   â””â”€â”€ Icons/
â”‚   â”œâ”€â”€ handlers/          # Business Logic
â”‚   â”‚   â”œâ”€â”€ chatHandler.ts
â”‚   â”‚   â”œâ”€â”€ imageHandler.ts
â”‚   â”‚   â””â”€â”€ visionHandler.ts
â”‚   â”œâ”€â”€ layouts/
â”‚   â”‚   â””â”€â”€ Layout.astro
â”‚   â”œâ”€â”€ libs/             # Utilities and Helpers
â”‚   â”‚   â”œâ”€â”€ chatFormHandler.ts
â”‚   â”‚   â””â”€â”€ getChatMessage.ts
â”‚   â”œâ”€â”€ types/           # TypeScript Definitions
â”‚   â”‚   â””â”€â”€ chat.ts
â”‚   â””â”€â”€ pages/
â”‚       â””â”€â”€ index.astro
```

## ğŸš€ Getting Started

1. **Clone the repository**

```bash
git clone <repository-url>
cd chat-bot
```

2. **Install dependencies**

```bash
npm install
```

3. **Set up Ollama**

- Make sure you have Ollama installed and running
- Download required models:

```bash
ollama pull llama3.2
ollama pull llama3.2-vision
```

4. **Start the development server**

```bash
npm run dev
```

5. **Build for production**

```bash
npm run build
```

## ğŸ“ Available Commands

| Command                 | Action                                      |
| :---------------------- | :------------------------------------------ |
| `npm install`           | Installs dependencies                       |
| `npm run dev`           | Starts local dev server at `localhost:4321` |
| `npm run build`         | Build your production site to `./dist/`     |
| `npm run preview`       | Preview your build locally                  |
| `npm test`              | Run tests                                   |
| `npm run test:ui`       | Run tests with UI                           |
| `npm run test:coverage` | Generate test coverage report               |

## ğŸ”§ Configuration

### TypeScript Configuration

The project uses a strict TypeScript configuration with custom path aliases for better import organization. Check `tsconfig.json` for details.

### Testing Configuration

Tests are configured using Vitest with the following features:

- Happy-DOM environment
- Coverage reporting
- Custom path aliases matching the main configuration

## ğŸ¨ Features in Detail

### Chat Interface

- Real-time message streaming
- Message history management
- Error handling and display
- Smooth scrolling to latest messages

### Image Handling

- Image upload and preview
- Base64 encoding for API compatibility
- File type validation
- Preview management

### Theme Management

- System theme detection
- Manual theme toggle
- Persistent theme preference
- Smooth transitions

## ğŸ“š API Integration

The project integrates with Ollama's API for both text and vision capabilities:

### Text Chat

- Model: `llama3.2:latest`
- Features:
  - Message streaming
  - Chat history management
  - Configurable temperature and top_p parameters

### Vision Chat

- Model: `llama3.2-vision:latest`
- Features:
  - Image processing
  - Base64 validation
  - Spanish language responses
  - Error handling

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.
